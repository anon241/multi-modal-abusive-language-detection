{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import Dataset, joint model and pytorch train helpers\n",
    "import transformers\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from dataset_parser.wich_parser import WichDataset\n",
    "from joint_model import JointModel\n",
    "from util.WeightedRandomSampler import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Wich train set from fixed split.\n",
      "Successfully loaded wich dataset.\n",
      "Loading Wich val set from fixed split.\n",
      "Successfully loaded wich dataset.\n",
      "Loading Wich test set from fixed split.\n",
      "Successfully loaded wich dataset.\n",
      "68443\n"
     ]
    }
   ],
   "source": [
    "# Open data set and split in train and dev and instantiate data loaders\n",
    "trainset, devset, testset  = WichDataset(fixed_set=\"train\"), WichDataset(fixed_set=\"val\"), WichDataset(fixed_set=\"test\")\n",
    "res = len(trainset) + len(devset) + len(testset)\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "sampler_trainset = WeightedRandomSampler(trainset, 5000)\n",
    "sampler_devset = WeightedRandomSampler(devset, 1000)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                        num_workers=6, sampler = sampler_trainset)\n",
    "devloader = torch.utils.data.DataLoader(devset, batch_size=1,\n",
    "                                        num_workers=6)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                        num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized TweetNetwork submodel\n",
      "Successfully initialized TweetClassifier submodel\n",
      "other done\n",
      "offensive done\n",
      "Successfully initialized TweetHistory submodel\n",
      "Successfully initialized last final classification layer\n"
     ]
    },
    {
     "data": {
      "text/plain": "JointModel(\n  (SAGE): GraphSAGE(\n    (model): SAGE(\n      (convs): ModuleList(\n        (0): SAGEConv(2, 32)\n        (1): SAGEConv(32, 32)\n        (2): SAGEConv(32, 32)\n      )\n    )\n  )\n  (BERT): TweetBERT(\n    (model): DistilBertForSequenceClassification(\n      (distilbert): DistilBertModel(\n        (embeddings): Embeddings(\n          (word_embeddings): Embedding(31102, 768, padding_idx=0)\n          (position_embeddings): Embedding(512, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (transformer): Transformer(\n          (layer): ModuleList(\n            (0): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (1): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (2): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (3): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (4): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (5): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n          )\n        )\n      )\n      (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n      (classifier): Linear(in_features=768, out_features=2, bias=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n  )\n  (BOW): TF_IDF_TweetHistory()\n  (simple_linear): Linear(in_features=534, out_features=2, bias=True)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate joint model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "joint_model = JointModel(dataset=\"wich\", random_subset_size=5000)\n",
    "joint_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load weights from trained model\n",
    "if \"cuda\" in str(device):\n",
    "    pass\n",
    "    joint_model.load_state_dict(torch.load('../../models/joint_model_wich_nulled_network_10epochs.model'))\n",
    "else:\n",
    "    print(\"check-else\")\n",
    "    joint_model.load_state_dict(torch.load('../../models/joint_model_wich_nulled_network_10epochs.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(joint_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 256\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-336d74ed52d7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtweet_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_ids\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0mattention_mask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtweet_label\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjoint_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muser_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtweet_label\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0mrunning_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Train joint model\n",
    "print (\"Batch size: {}\".format(BATCH_SIZE))\n",
    "for epoch in range(10):\n",
    "    #break\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        input_ids, attention_mask, user_id, tweet_label = data['input_ids'], data['attention_mask'], data['userid'], data['label'] #TODO fix this mess\n",
    "        input_ids, attention_mask, tweet_label = input_ids.to(device),  attention_mask.to(device), tweet_label.to(device)\n",
    "        predictions = joint_model(input_ids,attention_mask, user_id)\n",
    "        loss = criterion(predictions, tweet_label)\n",
    "        loss.backward()\n",
    "        running_loss += loss\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i % 4 == 0:\n",
    "            print (\"Epoch {}: {} tweets processed\".format(epoch, i*BATCH_SIZE))\n",
    "#torch.save(joint_model.state_dict(), \"../../models/joint_model_wich_nulled_network_10epochs.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-8297eb9e463c>:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = torch.nn.functional.softmax(predictions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "# Obtain predictions for the dev/validation set.\n",
    "y_pred, y_true = [],[]\n",
    "output_for_print = []\n",
    "for i, data in enumerate(devloader):\n",
    "    joint_model.eval()\n",
    "    input_ids, attention_mask, user_id, tweet_label = data['input_ids'], data['attention_mask'], data['userid'], data['label'] #TODO fix this mess\n",
    "    input_ids, attention_mask, tweet_label = input_ids.to(device),  attention_mask.to(device), tweet_label.to(device)\n",
    "    predictions = joint_model(input_ids,attention_mask, user_id)\n",
    "    predictions = torch.nn.functional.softmax(predictions)\n",
    "    max_pred = torch.argmax(predictions)\n",
    "    y_pred.append(max_pred.item())\n",
    "    y_true.append(tweet_label.item())\n",
    "    output_for_print.append([i,user_id.item(),tweet_label.item(),max_pred.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#print (confusion_matrix(y_true=y_true, y_pred=y_pred))\n",
    "#print (classification_report(y_true=y_true, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Obtain predictions for the test set.\n",
    "test_y_pred, test_y_true = [],[]\n",
    "for i, data in enumerate(testloader):\n",
    "    joint_model.eval()\n",
    "    input_ids, attention_mask, user_id, tweet_label = data['input_ids'], data['attention_mask'], data['userid'], data['label'] #TODO fix this mess\n",
    "    input_ids, attention_mask, tweet_label = input_ids.to(device),  attention_mask.to(device), tweet_label.to(device)\n",
    "#    print(input_ids, tweet_label)\n",
    "    test_predictions = joint_model(input_ids,attention_mask, user_id,shap=True,set_GRAPH_to_NULL = True)\n",
    "    test_predictions = torch.nn.functional.softmax(test_predictions)\n",
    "    test_max_pred = torch.argmax(test_predictions)\n",
    "    test_y_pred.append(test_max_pred.item())\n",
    "    test_y_true.append(tweet_label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-4b95f93bb33e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Print metrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mconfusion_matrix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_y_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_y_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mclassification_report\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_y_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_y_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdigits\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Print metrics\n",
    "print (confusion_matrix(y_true=test_y_true, y_pred=test_y_pred))\n",
    "print (classification_report(y_true=test_y_true, y_pred=test_y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# SHAP computations with class ShapExplainer\n",
    "from SHAP.shap import ShapExplainer"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Shapley configuration\n",
    "tweet_as_one = True\n",
    "vocab_as_one=True\n",
    "network_as_one = True\n",
    "untokenize = True\n",
    "dataset = 'wich'\n",
    "tokenizer_b = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-german-cased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainer = ShapExplainer(joint_model, tweet_as_one = tweet_as_one, vocab_as_one=vocab_as_one, network_as_one = network_as_one, dataset = dataset, untokenize = untokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-9254f23815b9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mtest_predictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctional\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_predictions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mtest_max_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_predictions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0mshapley_values\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredicted_class\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeature_distribution\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvocab_indices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_explainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapproximate_shap_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muser_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m     \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer_b\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_ids_to_tokens\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip_special_tokens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer_b\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_tokens_to_string\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/xai-lab-course-hater-networks/src/SHAP/shap.py\u001B[0m in \u001B[0;36mapproximate_shap_values\u001B[0;34m(self, input_ids, attention_mask, user_id)\u001B[0m\n\u001B[1;32m    139\u001B[0m                         \u001B[0mnodes_to_delete_in_SHAP\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m                 \u001B[0mprediction_with\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_to_explain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madjusted_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muser_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvocab_as_one\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mset_Tweet_to_NULL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mset_BOW_to_NULL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mset_GRAPH_to_NULL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madjusted_user_vocab\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnodes_to_delete_in_SHAP\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m                 \u001B[0mprediction_with\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctional\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprediction_with\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/xai-lab-course-hater-networks/src/joint_model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, tweet_input_ids, attention_mask, user_id, shap, vocab_as_one, set_Tweet_to_NULL, set_BOW_to_NULL, set_GRAPH_to_NULL, adjusted_user_vocab, nodes_to_delete_in_SHAP)\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mresult\u001B[0m \u001B[0mof\u001B[0m \u001B[0mclassifier\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0msimple\u001B[0m \u001B[0mlinear\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0mtrained\u001B[0m \u001B[0mon\u001B[0m \u001B[0mthe\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstatic\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0moutput\u001B[0m \u001B[0mof\u001B[0m \u001B[0mall\u001B[0m \u001B[0mthree\u001B[0m \u001B[0mmodels\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \"\"\"\n\u001B[0;32m---> 44\u001B[0;31m         \u001B[0mx1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBERT\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtweet_input_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;31m#x1.squeeze_() # removes batch dimension from bert output\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[0mx2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSAGE\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnodes_to_delete_in_SHAP\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# batch dim has been removed in forward pass of SAGE model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/xai-lab-course-hater-networks/src/TweetClassifier/distilbert_sequence_classifier.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask)\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mresult\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mDistilBERT\u001B[0m \u001B[0mclassifier\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0mwithout\u001B[0m \u001B[0msoftmax\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m         \"\"\"\n\u001B[0;32m---> 42\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;31m#for batchsize = 1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpretrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    618\u001B[0m             \u001B[0moutput_attentions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    619\u001B[0m             \u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 620\u001B[0;31m             \u001B[0mreturn_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_dict\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    621\u001B[0m         )\n\u001B[1;32m    622\u001B[0m         \u001B[0mhidden_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdistilbert_output\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# (bs, seq_len, dim)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    485\u001B[0m             \u001B[0moutput_attentions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    486\u001B[0m             \u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 487\u001B[0;31m             \u001B[0mreturn_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_dict\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    488\u001B[0m         )\n\u001B[1;32m    489\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    308\u001B[0m             layer_outputs = layer_module(\n\u001B[0;32m--> 309\u001B[0;31m                 \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhidden_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattn_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattn_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhead_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_attentions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    310\u001B[0m             )\n\u001B[1;32m    311\u001B[0m             \u001B[0mhidden_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer_outputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    265\u001B[0m         \u001B[0;31m# Feed Forward Network\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 266\u001B[0;31m         \u001B[0mffn_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mffn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msa_output\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# (bs, seq_length, dim)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    267\u001B[0m         \u001B[0mffn_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput_layer_norm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mffn_output\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0msa_output\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# (bs, seq_length, dim)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    216\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 217\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mapply_chunking_to_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mff_chunk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk_size_feed_forward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseq_len_dim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    218\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    219\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mff_chunk\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/transformers/modeling_utils.py\u001B[0m in \u001B[0;36mapply_chunking_to_forward\u001B[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[1;32m   1698\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput_chunks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mchunk_dim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1699\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1700\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mforward_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput_tensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001B[0m in \u001B[0;36mff_chunk\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    219\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mff_chunk\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlin1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 221\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactivation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    222\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlin2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/XAI/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mgelu\u001B[0;34m(input)\u001B[0m\n\u001B[1;32m   1381\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mTensor\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhas_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1382\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgelu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1383\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1384\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1385\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "shap_output = []\n",
    "for i, data in enumerate(testloader):\n",
    "    joint_model.eval()\n",
    "    input_ids, attention_mask, user_id, tweet_label = data['input_ids'], data['attention_mask'], data['userid'], data['label'] #TODO fix this mess\n",
    "    input_ids, attention_mask, tweet_label = input_ids.to(device),  attention_mask.to(device), tweet_label.to(device)\n",
    "    test_predictions = joint_model(input_ids,attention_mask, user_id)\n",
    "    test_predictions = torch.nn.functional.softmax(test_predictions)\n",
    "    test_max_pred = torch.argmax(test_predictions)\n",
    "    shapley_values, predicted_class, feature_distribution, vocab_indices = model_explainer.approximate_shap_values(input_ids, attention_mask, user_id)\n",
    "    res = tokenizer_b.convert_ids_to_tokens(input_ids[0], skip_special_tokens = True)\n",
    "    res = tokenizer_b.convert_tokens_to_string(res)\n",
    "    tweet_none = shapley_values[0,0].item()\n",
    "    vocab_none = shapley_values[0,1].item()\n",
    "    network_none = shapley_values[0,2].item()\n",
    "    \n",
    "    shap_output.append([i,user_id.item(),tweet_label.item(),test_max_pred.item(),tweet_none,vocab_none,network_none,res])\n",
    "    if i % 250 == 0:\n",
    "        print(i)\n",
    "# Now use the blocks specified in SHAP_plots.ipynb to get SHAP visualizations for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(shap_output)\n",
    "df.to_excel(\"shap.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6296  251]\n",
      " [ 173 1181]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.962     0.967      6547\n",
      "           1      0.825     0.872     0.848      1354\n",
      "\n",
      "    accuracy                          0.946      7901\n",
      "   macro avg      0.899     0.917     0.908      7901\n",
      "weighted avg      0.948     0.946     0.947      7901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print metrics\n",
    "print (confusion_matrix(y_true=test_y_true, y_pred=test_y_pred))\n",
    "print (classification_report(y_true=test_y_true, y_pred=test_y_pred, digits=3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}