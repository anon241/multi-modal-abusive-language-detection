{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import Dataset, joint model and pytorch train helpers\n",
    "import transformers\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from dataset_parser.davidson_parser import DavidsonDataset\n",
    "from joint_model import JointModel\n",
    "from util.WeightedRandomSampler import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Davidson train set from fixed split.\n",
      "Successfully loaded davidson dataset.\n",
      "Loading Davidson val set from fixed split.\n",
      "Successfully loaded davidson dataset.\n",
      "Loading Davidson test set from fixed split.\n",
      "Successfully loaded davidson dataset.\n",
      "14939\n"
     ]
    }
   ],
   "source": [
    "# Open data set and split in train and dev and instantiate data loaders\n",
    "trainset, devset, testset  = DavidsonDataset(fixed_set=\"train\"), DavidsonDataset(fixed_set=\"val\"), DavidsonDataset(fixed_set=\"test\")\n",
    "res = len(trainset) + len(devset) + len(testset)\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "sampler_trainset = WeightedRandomSampler(trainset, 3000)\n",
    "sampler_devset = WeightedRandomSampler(devset, 1000)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                        num_workers=6, sampler = sampler_trainset)\n",
    "devloader = torch.utils.data.DataLoader(devset, batch_size=1,\n",
    "                                        num_workers=6)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                        num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized TweetNetwork submodel\n",
      "Successfully initialized TweetClassifier submodel\n",
      "hate done\n",
      "offensive done\n",
      "neither done\n",
      "Successfully initialized TweetHistory submodel\n",
      "Successfully initialized last final classification layer\n"
     ]
    },
    {
     "data": {
      "text/plain": "JointModel(\n  (SAGE): GraphSAGE(\n    (model): SAGE(\n      (convs): ModuleList(\n        (0): SAGEConv(2, 32)\n        (1): SAGEConv(32, 32)\n        (2): SAGEConv(32, 32)\n      )\n    )\n  )\n  (BERT): TweetBERT(\n    (model): DistilBertForSequenceClassification(\n      (distilbert): DistilBertModel(\n        (embeddings): Embeddings(\n          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n          (position_embeddings): Embedding(512, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (transformer): Transformer(\n          (layer): ModuleList(\n            (0): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (1): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (2): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (3): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (4): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n            (5): TransformerBlock(\n              (attention): MultiHeadSelfAttention(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (ffn): FFN(\n                (dropout): Dropout(p=0.1, inplace=False)\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            )\n          )\n        )\n      )\n      (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n      (classifier): Linear(in_features=768, out_features=3, bias=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n  )\n  (BOW): TF_IDF_TweetHistory()\n  (simple_linear): Linear(in_features=535, out_features=3, bias=True)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate joint model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "joint_model = JointModel()\n",
    "joint_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load weights from trained model\n",
    "if \"cuda\" in str(device):\n",
    "    pass\n",
    "    joint_model.load_state_dict(torch.load('../../models/joint_model_davidson_nulled_network_10epochs.model'))\n",
    "else:\n",
    "    print(\"check-else\")\n",
    "    joint_model.load_state_dict(torch.load('../../models/joint_model_davidson_nulled_network_10epochs.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(joint_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 256\n",
      "Epoch 0: 0 tweets processed\n",
      "Epoch 0: 1024 tweets processed\n",
      "Epoch 0: 2048 tweets processed\n",
      "Epoch 0: 3072 tweets processed\n",
      "Epoch 0: 4096 tweets processed\n",
      "Epoch 0: 5120 tweets processed\n",
      "Epoch 0: 6144 tweets processed\n",
      "Epoch 0: 7168 tweets processed\n",
      "Epoch 0: 8192 tweets processed\n",
      "Epoch 1: 0 tweets processed\n",
      "Epoch 1: 1024 tweets processed\n",
      "Epoch 1: 2048 tweets processed\n",
      "Epoch 1: 3072 tweets processed\n",
      "Epoch 1: 4096 tweets processed\n",
      "Epoch 1: 5120 tweets processed\n",
      "Epoch 1: 6144 tweets processed\n",
      "Epoch 1: 7168 tweets processed\n",
      "Epoch 1: 8192 tweets processed\n",
      "Epoch 2: 0 tweets processed\n",
      "Epoch 2: 1024 tweets processed\n",
      "Epoch 2: 2048 tweets processed\n",
      "Epoch 2: 3072 tweets processed\n",
      "Epoch 2: 4096 tweets processed\n",
      "Epoch 2: 5120 tweets processed\n",
      "Epoch 2: 6144 tweets processed\n",
      "Epoch 2: 7168 tweets processed\n",
      "Epoch 2: 8192 tweets processed\n",
      "Epoch 3: 0 tweets processed\n",
      "Epoch 3: 1024 tweets processed\n",
      "Epoch 3: 2048 tweets processed\n",
      "Epoch 3: 3072 tweets processed\n",
      "Epoch 3: 4096 tweets processed\n",
      "Epoch 3: 5120 tweets processed\n",
      "Epoch 3: 6144 tweets processed\n",
      "Epoch 3: 7168 tweets processed\n",
      "Epoch 3: 8192 tweets processed\n",
      "Epoch 4: 0 tweets processed\n",
      "Epoch 4: 1024 tweets processed\n",
      "Epoch 4: 2048 tweets processed\n",
      "Epoch 4: 3072 tweets processed\n",
      "Epoch 4: 4096 tweets processed\n",
      "Epoch 4: 5120 tweets processed\n",
      "Epoch 4: 6144 tweets processed\n",
      "Epoch 4: 7168 tweets processed\n",
      "Epoch 4: 8192 tweets processed\n",
      "Epoch 5: 0 tweets processed\n",
      "Epoch 5: 1024 tweets processed\n",
      "Epoch 5: 2048 tweets processed\n",
      "Epoch 5: 3072 tweets processed\n",
      "Epoch 5: 4096 tweets processed\n",
      "Epoch 5: 5120 tweets processed\n",
      "Epoch 5: 6144 tweets processed\n",
      "Epoch 5: 7168 tweets processed\n",
      "Epoch 5: 8192 tweets processed\n",
      "Epoch 6: 0 tweets processed\n",
      "Epoch 6: 1024 tweets processed\n",
      "Epoch 6: 2048 tweets processed\n",
      "Epoch 6: 3072 tweets processed\n",
      "Epoch 6: 4096 tweets processed\n",
      "Epoch 6: 5120 tweets processed\n",
      "Epoch 6: 6144 tweets processed\n",
      "Epoch 6: 7168 tweets processed\n",
      "Epoch 6: 8192 tweets processed\n",
      "Epoch 7: 0 tweets processed\n",
      "Epoch 7: 1024 tweets processed\n",
      "Epoch 7: 2048 tweets processed\n",
      "Epoch 7: 3072 tweets processed\n",
      "Epoch 7: 4096 tweets processed\n",
      "Epoch 7: 5120 tweets processed\n",
      "Epoch 7: 6144 tweets processed\n",
      "Epoch 7: 7168 tweets processed\n",
      "Epoch 7: 8192 tweets processed\n",
      "Epoch 8: 0 tweets processed\n",
      "Epoch 8: 1024 tweets processed\n",
      "Epoch 8: 2048 tweets processed\n",
      "Epoch 8: 3072 tweets processed\n",
      "Epoch 8: 4096 tweets processed\n",
      "Epoch 8: 5120 tweets processed\n",
      "Epoch 8: 6144 tweets processed\n",
      "Epoch 8: 7168 tweets processed\n",
      "Epoch 8: 8192 tweets processed\n",
      "Epoch 9: 0 tweets processed\n",
      "Epoch 9: 1024 tweets processed\n",
      "Epoch 9: 2048 tweets processed\n",
      "Epoch 9: 3072 tweets processed\n",
      "Epoch 9: 4096 tweets processed\n",
      "Epoch 9: 5120 tweets processed\n",
      "Epoch 9: 6144 tweets processed\n",
      "Epoch 9: 7168 tweets processed\n",
      "Epoch 9: 8192 tweets processed\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Train joint model\n",
    "print (\"Batch size: {}\".format(BATCH_SIZE))\n",
    "for epoch in range(10):\n",
    "    #break\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        input_ids, attention_mask, user_id, tweet_label = data['input_ids'], data['attention_mask'], data['userid'], data['label'] #TODO fix this mess\n",
    "        input_ids, attention_mask, tweet_label = input_ids.to(device),  attention_mask.to(device), tweet_label.to(device)\n",
    "        predictions = joint_model(input_ids,attention_mask, user_id)\n",
    "        loss = criterion(predictions, tweet_label)\n",
    "        loss.backward()\n",
    "        running_loss += loss\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i % 4 == 0:\n",
    "            print (\"Epoch {}: {} tweets processed\".format(epoch, i*BATCH_SIZE))\n",
    "torch.save(joint_model.state_dict(), \"../../models/joint_model_davidson_nulled_network_10epochs.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-449a3978ca05>:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = torch.nn.functional.softmax(predictions)\n"
     ]
    }
   ],
   "source": [
    "# Obtain predictions for the dev/validation set.\n",
    "y_pred, y_true = [],[]\n",
    "output_for_print = []\n",
    "for i, data in enumerate(devloader):\n",
    "    joint_model.eval()\n",
    "    input_ids, attention_mask, user_id, tweet_label = data['input_ids'], data['attention_mask'], data['userid'], data['label'] #TODO fix this mess\n",
    "    input_ids, attention_mask, tweet_label = input_ids.to(device),  attention_mask.to(device), tweet_label.to(device)\n",
    "    predictions = joint_model(input_ids,attention_mask, user_id)\n",
    "    predictions = torch.nn.functional.softmax(predictions)\n",
    "    max_pred = torch.argmax(predictions)\n",
    "    y_pred.append(max_pred.item())\n",
    "    y_true.append(tweet_label.item())\n",
    "    output_for_print.append([i,user_id.item(),tweet_label.item(),max_pred.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#print (confusion_matrix(y_true=y_true, y_pred=y_pred))\n",
    "#print (classification_report(y_true=y_true, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xx/.conda/envs/XAI/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "exit()\n",
    "# Obtain predictions for the test set.\n",
    "test_y_pred, test_y_true = [],[]\n",
    "output_for_print = []\n",
    "for i, data in enumerate(testloader):\n",
    "    joint_model.eval()\n",
    "    input_ids, attention_mask, user_id, tweet_label = data['input_ids'], data['attention_mask'], data['userid'], data['label'] #TODO fix this mess\n",
    "    input_ids, attention_mask, tweet_label = input_ids.to(device),  attention_mask.to(device), tweet_label.to(device)\n",
    "    test_predictions = joint_model(input_ids,attention_mask, user_id)\n",
    "    test_predictions = torch.nn.functional.softmax(test_predictions)\n",
    "    test_max_pred = torch.argmax(test_predictions)\n",
    "    test_y_pred.append(test_max_pred.item())\n",
    "    test_y_true.append(tweet_label.item())\n",
    "    output_for_print.append([i,user_id.item(),tweet_label.item(),test_max_pred.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  67   48   13]\n",
      " [  77 1929   54]\n",
      " [  14   24  374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.52      0.47       128\n",
      "           1       0.96      0.94      0.95      2060\n",
      "           2       0.85      0.91      0.88       412\n",
      "\n",
      "    accuracy                           0.91      2600\n",
      "   macro avg       0.75      0.79      0.77      2600\n",
      "weighted avg       0.92      0.91      0.91      2600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print metrics\n",
    "print (confusion_matrix(y_true=test_y_true, y_pred=test_y_pred))\n",
    "print (classification_report(y_true=test_y_true, y_pred=test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP computations with class ShapExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SHAP.shap import ShapExplainer\n",
    "# Shapley configuration\n",
    "tweet_as_one = True\n",
    "vocab_as_one=True\n",
    "network_as_one = False\n",
    "untokenize = True\n",
    "dataset = 'davidson'\n",
    "\n",
    "tokenizer_d = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainer = ShapExplainer(joint_model, tweet_as_one = tweet_as_one, vocab_as_one=vocab_as_one, network_as_one = network_as_one, dataset = dataset, untokenize = untokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6723\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6723\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6723\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6723\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6723\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6712\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6723\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6724\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6713\n",
      "6725\n",
      "6712\n",
      "6725\n",
      "6714\n",
      "6725\n",
      "6713\n",
      "-0.01418756227940321\n",
      "-0.0033643802162259817\n",
      "0.017551971599459648\n",
      "@ i can guarantee a few things : you ' re white . you ' ve never been anywhere near a real ghetto . you , or a relative is a pig . 100 %\n"
     ]
    }
   ],
   "source": [
    "test_y_pred, test_y_true = [],[]\n",
    "shap_output = []\n",
    "for i, data in enumerate(testloader):\n",
    "    if i != 470:\n",
    "        continue\n",
    "    joint_model.eval()\n",
    "    input_ids, attention_mask, user_id, tweet_label = data['input_ids'], data['attention_mask'], data['userid'], data['label'] #TODO fix this mess\n",
    "    input_ids, attention_mask, tweet_label = input_ids.to(device),  attention_mask.to(device), tweet_label.to(device)\n",
    "    test_predictions = joint_model(input_ids,attention_mask, user_id)\n",
    "    test_predictions = torch.nn.functional.softmax(test_predictions)\n",
    "    test_max_pred = torch.argmax(test_predictions)\n",
    "    shapley_values, predicted_class, feature_distribution, vocab_indices = model_explainer.approximate_shap_values(input_ids, attention_mask, user_id)\n",
    "    res = tokenizer_d.convert_ids_to_tokens(input_ids[0], skip_special_tokens = True)\n",
    "    res = tokenizer_d.convert_tokens_to_string(res)\n",
    "    tweet_hate = shapley_values[0,0].item()\n",
    "    tweet_offen = shapley_values[1,0].item()\n",
    "    tweet_none = shapley_values[2,0].item()\n",
    "    vocab_hate = shapley_values[0,1].item()\n",
    "    vocab_offen = shapley_values[1,1].item()\n",
    "    vocab_none = shapley_values[2,1].item()\n",
    "    network_hate = shapley_values[0,2].item()\n",
    "    network_offen = shapley_values[1,2].item()\n",
    "    network_none = shapley_values[2,2].item()\n",
    "    print (network_none)\n",
    "    print (network_offen)\n",
    "    print (network_hate)\n",
    "    #model_explainer.visualize_text_plot(shapley_values[0], input_ids)\n",
    "    #%%capture Jupyter notebook\n",
    "    #break\n",
    "    tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    res = tokenizer.convert_ids_to_tokens(input_ids[0], skip_special_tokens = True)\n",
    "\n",
    "    res = tokenizer.convert_tokens_to_string(res)\n",
    "    print(res)\n",
    "    tweet_hate,tweet_offen,tweet_none,vocab_hate,vocab_offen,vocab_none,network_hate,network_offen,network_none\n",
    "\n",
    "    shap_output.append([i,user_id.item(),shapley_values,test_max_pred])\n",
    "    #model_explainer.visualize_text_plot(shap_values=shapley_values, input_ids=input_ids)\n",
    "\n",
    "    if i % 250 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174612923\n",
      "253731715\n",
      "283237757\n",
      "345979063\n",
      "352976073\n",
      "35807273\n",
      "405676041\n",
      "4299309089\n",
      "52244066\n",
      "563835357\n",
      "772409804\n",
      "2239658598\n",
      "598759378\n",
      "0.017551971599459648\n",
      "708\n",
      "here\n",
      "-0.010394140146672726\n",
      "nothere\n",
      "0.006517278961837292\n",
      "14\n",
      "here\n",
      "{708: {'group': 0, 'direct_relation': 11, 'value': 30, 'label': '708, 0/11', 'color': '#fe004d'}, 64: {'group': 1, 'direct_relation': 1, 'value': 30, 'label': '64, 0/1', 'color': '#118cfe'}, 14: {'group': 2, 'direct_relation': 1, 'value': 30, 'label': '14, 0/1', 'color': '#fe004d'}}\n"
     ]
    }
   ],
   "source": [
    "#[i,user_id.item(),shapley_values, res, test_max_pred]]\n",
    "model_explainer.plot_network(shap_output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}